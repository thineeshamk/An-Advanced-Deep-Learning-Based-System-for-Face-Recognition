# -*- coding: utf-8 -*-
"""Custom CNN (Model 1) .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11-czpc_aaLrDl9UVRiQnx7SLj8YcBTvT
"""

import os
from PIL import Image
import numpy as np
from sklearn.model_selection import train_test_split

# Define the image folder and classes
image_folder = '/content/drive/MyDrive/Facial image recodnition'  # üîÅ Change this to your image folder path
class_names = os.listdir(image_folder)  # Assumes folder has subfolders for each class

IMG_SIZE = (224, 224)

def load_dataset(image_folder, img_size=(224, 224)):
    images = []
    labels = []
    class_indices = {class_name: idx for idx, class_name in enumerate(class_names)}

    for class_name in class_names:
        class_path = os.path.join(image_folder, class_name)
        for img_file in os.listdir(class_path):
            try:
                img_path = os.path.join(class_path, img_file)
                img = Image.open(img_path).convert("RGB")  # Removes alpha channel
                img = img.resize(img_size)
                img_array = np.array(img) / 255.0  # Normalize to [0, 1]
                images.append(img_array)
                labels.append(class_indices[class_name])
            except Exception as e:
                print(f"Failed to load {img_path}: {e}")

    return np.array(images), np.array(labels)

# Load dataset
X, y = load_dataset(image_folder, IMG_SIZE)

# Split into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

print("Dataset loaded successfully!")
print(f"Total samples: {len(X)}")
print(f"Training samples: {len(X_train)}, Validation samples: {len(X_val)}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(len(class_names), activation='softmax')  # Output layer
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))